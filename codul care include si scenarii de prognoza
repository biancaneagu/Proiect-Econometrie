############################################################################
# PROIECT ECONOMETRIE - APLICAȚIA 1 (VARIANTA COGNITIVE SCORE)
# TEMA: Determinanții Performanței Cognitive
############################################################################

rm(list = ls())

# --- 1. SETUP ---
# setwd("C:/Calea/Ta/Catre/Fisier") # <--- MODIFICĂ AICI DACA E NEVOIE

PackageNames <- c("tidyverse", "stargazer", "magrittr", "lmtest", "sandwich", 
                  "olsrr", "moments", "ggplot2", "tseries", "car", "caret", 
                  "MLmetrics", "factoextra", "cluster", "corrplot")

for(i in PackageNames){
  if(!require(i, character.only = T)){
    install.packages(i, dependencies = T)
    require(i, character.only = T)
  }
}

# --- 2. IMPORT ȘI PREGĂTIRE ---
raw_data <- read.csv("human_cognitive_performance.csv", header = TRUE)
df <- raw_data

# Transformări Dummy
df %<>% mutate(DummyGenderF = ifelse(Gender == "Female", 1, 0))
df %<>% mutate(DummyVegan = ifelse(Diet_Type == "Vegan", 1, 0))
df %<>% mutate(DummyExerciseHigh = ifelse(Exercise_Frequency == "High", 1, 0))

# !!! SCHIMBARE MAJORĂ AICI !!!
# Y = Cognitive_Score
# X = Sleep, Screen, Caffeine, Age, Dummies
df_final <- df %>% 
  dplyr::select(Cognitive_Score,     # <--- Noul Y
                Sleep_Duration,      
                Daily_Screen_Time,   
                Caffeine_Intake,     
                Age,                 
                DummyGenderF, DummyVegan, DummyExerciseHigh)

df_final <- na.omit(df_final)

# --- 3. ANALIZA EXPLORATORIE ---
stargazer(df_final, type = "text", title = "Statistici Descriptive (Cognitive Score)")

# Histograma Y
ggplot(df_final, aes(x = Cognitive_Score)) +
  geom_histogram(fill = "forestgreen", color = "white", bins = 15) +
  theme_minimal() + ggtitle("Distribuția Scorului Cognitiv")

# Matrice de Corelație
cor_matrix <- cor(df_final)
corrplot(cor_matrix, method = "number", type = "upper", tl.cex = 0.7)

# --- 4. CLUSTERING (K-MEANS OPTIMIZAT & STABIL) ---
# Vedem dacă există grupuri de performanță (ex: "High Performers" vs "Low Performers")

# Scalăm datele (obligatoriu pentru K-Means)
df_scaled <- scale(df_final)

set.seed(123)

# Calculăm clusterii folosind algoritmul "MacQueen" pentru a evita eroarea Quick-TRANSfer
km_res <- kmeans(df_scaled, 
                 centers = 3, 
                 nstart = 25, 
                 iter.max = 100,        # Creștem numărul de iterații
                 algorithm = "MacQueen") # <--- ASTA REZOLVĂ PROBLEMA

# Vizualizare pe eșantion mic (să nu crape memoria la grafic)
# Luăm maxim 2000 de puncte pentru desen
sample_n <- min(2000, nrow(df_scaled))
sample_idx <- sample(1:nrow(df_scaled), sample_n)

# Pregătim obiectul pentru vizualizare
km_viz <- list(data = df_scaled[sample_idx, ], cluster = km_res$cluster[sample_idx])
class(km_viz) <- "kmeans"

# Generăm graficul
fviz_cluster(km_viz, data = df_scaled[sample_idx, ],
             palette = "jco", 
             ggtheme = theme_minimal(), 
             geom = "point",
             main = "Tipologii de Performanță Cognitivă")

# --- 5. TRAIN / TEST SPLIT ---
set.seed(123)
# Atenție: împărțim pe baza Cognitive_Score acum
train_idx <- createDataPartition(df_final$Cognitive_Score, p = 0.8, list = FALSE)
train_data <- df_final[train_idx, ]
test_data  <- df_final[-train_idx, ]

# --- 6. MODELARE OLS (Y = Cognitive_Score) ---
model_ols <- lm(Cognitive_Score ~ Sleep_Duration + Daily_Screen_Time + Caffeine_Intake + 
                  Age + DummyGenderF + DummyVegan + DummyExerciseHigh, 
                data = train_data)

# Rezultate
stargazer(model_ols, type = "text", title = "Regresie: Determinanții Performanței Cognitive")

# =========================================================================
# CONTINUARE: VALIDARE ȘI PREDICȚIE (Cerințele 3.b și 3.c)
# =========================================================================

# 1. TESTE DE DIAGNOSTIC (Validarea ipotezelor)
cat("\n--- 1. Testul VIF (Multicoliniaritate) ---\n")
# Verificăm dacă variabilele sunt prea corelate între ele
vif_vals <- vif(model_ols)
print(vif_vals)
if(max(vif_vals) < 5) cat("Verdict: OK (Nu avem multicoliniaritate severă)\n")

cat("\n--- 2. Testul Breusch-Pagan (Homoscedasticitate) ---\n")
# H0: Erorile sunt constante (Homoscedasticitate)
# H1: Erorile sunt variabile (Heteroscedasticitate)
bp_test <- bptest(model_ols)
print(bp_test)

# --- CORECȚIE PENTRU HETEROSCEDASTICITATE ---
# Folosim estimatori robuști (Sandwich Estimator - HC1)
# Asta va ajusta "steluțele" și erorile standard, păstrând coeficienții la fel.

library(lmtest)
library(sandwich)

# Recalculăm tabelul de coeficienți cu erori robuste
model_robust <- coeftest(model_ols, vcov = vcovHC(model_ols, type = "HC1"))

# Afișăm noile rezultate corectate
print(model_robust)




cat("\n--- 3. Testul Jarque-Bera (Normalitate Reziduuri) ---\n")
# H0: Reziduurile sunt distribuite normal
resid_vals <- residuals(model_ols)
jb_test <- jarque.bera.test(resid_vals)
print(jb_test)
# NOTA: La 64.000 de observații, testele de normalitate pică des (p < 0.05).
# Te bazezi pe "Teorema Limitei Centrale" (CLT) care spune că OLS e valid pe eșantioane mari.

cat("\n--- 4. Testul Durbin-Watson (Autocorelare) ---\n")
# Valori intre 1.8 si 2.2 sunt ideale.
dw_test <- dwtest(model_ols)
print(dw_test)




# =========================================================================
# 5. EVALUAREA CAPACITĂȚII PREDICTIVE (Cerința 3.c) - VERSIUNEA CORECTATĂ
# =========================================================================

# 1. Facem predicții pe setul de TEST (date pe care modelul NU le-a văzut)
pred_test <- predict(model_ols, newdata = test_data)

# 2. Definim o funcție sigură pentru MAPE (evită împărțirea la zero)
# Dacă valoarea reală e 0, o tratăm ca 0.01 pentru a putea face calculul matematic.
calculate_safe_mape <- function(actual, pred){
  # Formula: media diferenței absolute procentuale
  mean(abs((actual - pred) / pmax(actual, 0.01))) * 100
}

# 3. Calculăm indicatorii de performanță
# RMSE (Root Mean Squared Error) - penalizează erorile mari
rmse_val <- RMSE(pred_test, test_data$Cognitive_Score)

# MAE (Mean Absolute Error) - eroarea medie în puncte
mae_val  <- MAE(pred_test, test_data$Cognitive_Score)

# MAPE (Calculat cu funcția noastră sigură)
mape_val <- calculate_safe_mape(test_data$Cognitive_Score, pred_test)

# R2 pe setul de testare (Stabilitatea modelului)
r2_test  <- R2_Score(pred_test, test_data$Cognitive_Score)

# 4. Afișăm Raportul Final
cat("\n=======================================================\n")
cat(" RAPORT FINAL DE PERFORMANȚĂ (Set Testare - 20%)\n")
cat("=======================================================\n")
cat("RMSE (Eroarea Medie Pătratică):   ", round(rmse_val, 4), "puncte\n")
cat("MAE  (Eroarea Medie Absolută):    ", round(mae_val, 4), "puncte\n")
cat("MAPE (Eroarea Procentuală):       ", round(mape_val, 2), "%\n")
cat("R2 Score (Pe date noi):           ", round(r2_test, 4), "\n")
cat("-------------------------------------------------------\n")
# Verificare Overfitting
diff_r2 <- abs(summary(model_ols)$adj.r.squared - r2_test)
if(diff_r2 < 0.05){
  cat("CONCLUZIE: Modelul este ROBUST (Nu există Overfitting).\n")
  cat("Diferența dintre R2 Train și R2 Test este mică:", round(diff_r2, 4), "\n")
} else {
  cat("CONCLUZIE: Există semne de Overfitting (Diferență mare între Train și Test).\n")
}
cat("=======================================================\n")



# =========================================================================
# CERINȚA 4: SCENARII DE PROGNOZĂ
# =========================================================================

# 1. Definim Profilurile Ipotetice
scenarii <- data.frame(
  Name = c("Studentul Ideal", "Studentul Extenuat"),
  Sleep_Duration = c(9, 4),           # 9 ore vs 4 ore
  Daily_Screen_Time = c(1, 10),       # 1 oră vs 10 ore
  Caffeine_Intake = c(50, 400),       # 50mg vs 400mg
  Age = c(22, 22),                    # Aceeași vârstă
  DummyGenderF = c(0, 0),             # Ambii bărbați (pentru comparație)
  DummyVegan = c(0, 0),               # Niciunul vegan
  DummyExerciseHigh = c(1, 0)         # Unul face sport intens, celălalt nu
)

# 2. Facem Prognoza (cu Interval de Încredere 95%)
prognoza <- predict(model_ols, newdata = scenarii, interval = "confidence", level = 0.95)

# 3. Combinăm datele pentru afișare
rezultat_scenarii <- cbind(scenarii[, c("Name", "Sleep_Duration", "Daily_Screen_Time", "DummyExerciseHigh")], prognoza)

# 4. Afișăm Rezultatul
cat("\n=======================================================\n")
cat(" SCENARII DE PROGNOZĂ: CUM INFLUENȚEAZĂ STILUL DE VIAȚĂ?\n")
cat("=======================================================\n")
print(rezultat_scenarii)
cat("-------------------------------------------------------\n")
cat("Interpretare:\n")
diff_score <- prognoza[1, "fit"] - prognoza[2, "fit"]
cat("Diferența de scor cognitiv între stilul de viață sănătos și cel extenuat\n")
cat("este de aproximativ:", round(diff_score, 2), "puncte.\n")
cat("=======================================================\n")
